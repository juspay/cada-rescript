{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.9 environment at: /Users/sakthi.n/Documents/Opensource/cada-rescript/tvenv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m8 packages\u001b[0m \u001b[2min 1.63s\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 177ms\u001b[0m\u001b[0m                                              \n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m (from git+https://github.com/tree\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtree-sitter\u001b[0m\u001b[2m==0.24.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtree-sitter\u001b[0m\u001b[2m==0.24.0 (from git+https://github.com/tree-sitter/py-tree-sitter@9c78f3b8d10f81b97fbb2181c9333323d6375480)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install -U git+https://github.com/JignyasAnand/rescript-ast-diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.9 environment at: /Users/sakthi.n/Documents/Opensource/cada-rescript/tvenv\u001b[0m\n",
      "\u001b[2K   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m ssh://git@ssh.bitbucket.juspay.net/iris/jaf.git (\u001b[2mcode-traverse\u001b[0m)\n",
      "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m ssh://git@ssh.bitbucket.juspay.net/iris/jaf.git (\u001b[2mcode-traverse\u001b[0m)\n",
      "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m ssh://git@ssh.bitbucket.juspay.net/iris/jaf.git (\u001b[2mcode-traverse\u001b[0m)\n",
      "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m ssh://git@ssh.bitbucket.juspay.net/iris/jaf.git (\u001b[2mcode-traverse\u001b[0m)\n",
      "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m ssh://git@ssh.bitbucket.juspay.net/iris/jaf.git (\u001b[2mcode-traverse\u001b[0m)\n",
      "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m ssh://git@ssh.bitbucket.juspay.net/iris/jaf.git (\u001b[2mcode-traverse\u001b[0m)\n",
      "\u001b[2K\u001b[1A    \u001b[32m\u001b[1mUpdated\u001b[0m\u001b[39m ssh://git@ssh.bitbucket.juspay.net/iris/jaf.git (\u001b[2mc6e993245059088eb09f8ae\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m38 packages\u001b[0m \u001b[2min 989ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2mAudited \u001b[1m38 packages\u001b[0m \u001b[2min 0.07ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install git+ssh://git@ssh.bitbucket.juspay.net/iris/jaf.git@code-traverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATEST COMMIT - 41256f7b31a489df4cc57dddc4e4ae4f2cf7fe36\n",
      "OLDEST COMMIT - 7dcd1a179f54f2f93dea9f2a82ea7ce3dfe89296\n",
      "Changes written to -  ./detailed_changes.json\n"
     ]
    }
   ],
   "source": [
    "from rescript_ast_diff import generate_pr_changes_bitbucket\n",
    "from rescript_ast_diff.bitbucket import BitBucket \n",
    "\n",
    "BASE_URL = \"https://bitbucket.juspay.net/rest\"\n",
    "PROJECT_KEY = \"JBIZ\"\n",
    "REPO_SLUG = \"rescript-euler-dashboard\"\n",
    "AUTH = (\"sakthi.n@juspay.in\", \"BBDC-NDg5ODgwNDM2MzkyOjgy8c70YxFmjQlfjSGQD4895tx5\")\n",
    "HEADERS = {\"Accept\": \"application/json\"}\n",
    "PR_ID = \"19971\"\n",
    "bitbucket = BitBucket(BASE_URL, PROJECT_KEY, REPO_SLUG, AUTH, HEADERS)\n",
    "generate_pr_changes_bitbucket(PR_ID, bitbucket, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaf.core.llm import AzureGPTLLM\n",
    "from dotenv import load_dotenv \n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_GPT_DEPLOYMENT_NAME=os.getenv(\"AZURE_GPT_DEPLOYMENT_NAME\")\n",
    "AZURE_OAI_BASE_URL=os.getenv(\"AZURE_OAI_BASE_URL\")\n",
    "AZURE_OAI_API_VERSION= os.getenv(\"AZURE_OAI_API_VERSION\")\n",
    "AZURE_OAI_API_KEY= os.getenv(\"AZURE_OAI_API_KEY\")\n",
    "\n",
    "llm = AzureGPTLLM(\n",
    "    deployment_name=AZURE_GPT_DEPLOYMENT_NAME,\n",
    "    api_base=AZURE_OAI_BASE_URL,\n",
    "    api_version=AZURE_OAI_API_VERSION,\n",
    "    api_key=AZURE_OAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "class Data(BaseModel):\n",
    "   moduleName: str\n",
    "   addedFunctions: list = []\n",
    "   modifiedFunctions: list = []\n",
    "   deletedFunctions: list = []\n",
    "   addedTypes: list = []\n",
    "   modifiedTypes: list = []\n",
    "   deletedTypes: list = []\n",
    "   addedExternals: list = []\n",
    "   modifiedExternals: list = []\n",
    "   deletedExternals: list = []\n",
    "   # prompt: Optional[str] = \"\" \n",
    "   testCases: Optional[list] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../python/detailed_changes.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "result = []\n",
    "for d in data:\n",
    "    result.append(Data.model_validate(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemPrompt = \"\"\" \n",
    "You are a QA automation assistant. Given code changes to frontend components or functions (added or modified), generate structured test case objects in JSON format.\n",
    "\n",
    "Each test case must contain:\n",
    "\n",
    "testCaseId: Unique identifier (e.g., TC001, TC002)\n",
    "\n",
    "description: One-line summary of what the test verifies\n",
    "\n",
    "stepsToReproduce: A list of precise UI actions (e.g., \"Click button\", \"Enter value in input\")\n",
    "\n",
    "expectedResult: What the correct outcome should be\n",
    "\n",
    "⚠️ Steps must be realistic, like how a manual tester would execute them.\n",
    "❌ Avoid vague steps like \"Run function\" — describe the UI interaction instead.\n",
    "\n",
    "Output a JSON array of such test cases.\n",
    "\n",
    "If there are no test cases (e.g., only deletions), return an empty list [].\n",
    "\n",
    "Eg Format:\n",
    "[\n",
    "  {\n",
    "    \"testCaseId\": \"TC001\",\n",
    "    \"description\": \"User can successfully search when input is valid\",\n",
    "    \"stepsToReproduce\": [\n",
    "      \"Navigate to the Search page\",\n",
    "      \"Enter 'apple' in the search input box\",\n",
    "      \"Click the 'Search' button\"\n",
    "    ],\n",
    "    \"expectedResult\": \"Search results are displayed for 'apple'\"\n",
    "  },\n",
    "  {\n",
    "    \"testCaseId\": \"TC002\",\n",
    "    \"description\": \"Search button does nothing if query is too short\",\n",
    "    \"stepsToReproduce\": [\n",
    "      \"Navigate to the Search page\",\n",
    "      \"Enter 'ap' in the search input box\",\n",
    "      \"Click the 'Search' button\"\n",
    "    ],\n",
    "    \"expectedResult\": \"No search is performed; no request sent\"\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "userPrompt = \"\"\"\n",
    "Here are the frontend code changes in this pull request.\n",
    "Please generate test cases in JSON format, following this structure:\n",
    "[\n",
    "  {{\n",
    "    \"testCaseId\": \"TC001\",\n",
    "    \"description\": \"What the test is verifying\",\n",
    "    \"stepsToReproduce\": [\n",
    "      \"Step 1\",\n",
    "      \"Step 2\",\n",
    "      \"...\"\n",
    "    ],\n",
    "    \"expectedResult\": \"Expected behavior\"\n",
    "  }},\n",
    "  {{\n",
    "    \"testCaseId\": \"TC002\",\n",
    "    \"description\": \"What the test is verifying\",\n",
    "    \"stepsToReproduce\": [\n",
    "      \"Step 1\",\n",
    "      \"Step 2\",\n",
    "      \"...\"\n",
    "    ],\n",
    "    \"expectedResult\": \"Expected behavior\"\n",
    "  }}\n",
    "  ...\n",
    "]\n",
    "Be realistic and user-centric in the steps — describe UI actions like clicking, typing, navigation, etc.\n",
    "Generate test cases only for added or modified functions or components.\n",
    "Ignore deleted functions unless they affect user-facing behavior.\n",
    "\n",
    "Added Functions/Components:\n",
    "{added}\n",
    "\n",
    "Modified Functions/Components:\n",
    "{modified}\n",
    "\n",
    "Deleted Functions/Components:\n",
    "{deleted}\n",
    "\n",
    "Based on the above things \n",
    "Return the test cases as a JSON array.\n",
    "Do not include any extra commentary or explanation — just valid JSON.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse(text: str) -> dict:\n",
    "    cleaned = re.sub(r\"```(?:json)?\", \"\", text).strip()\n",
    "    \n",
    "    # Try parsing it\n",
    "    try:\n",
    "        parsed = json.loads(cleaned)\n",
    "        return parsed\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"❌ Failed to parse JSON:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src/entryPoints/pgIntegration/PgIntegrationApp.res\n",
      "src/libraries/Monaco.res\n",
      "src/libraries/MonacoEditor.res\n",
      "src/libraries/ReactDiffViewer.res\n",
      "src/screens/PGintegration/AddedFeauture.res\n",
      "src/screens/PGintegration/CreateNewFeature.res\n",
      "src/screens/PGintegration/FilledEntryFields.res\n",
      "src/screens/PGintegration/GenerateResponseViewer.res\n",
      "src/screens/PGintegration/InitialScreen.res\n",
      "src/screens/PGintegration/IntegrationChecklist.res\n",
      "src/screens/PGintegration/IntegrationFlow.res\n",
      "src/screens/PGintegration/IntegrationRouterTabs.res\n",
      "src/screens/PGintegration/MultiApiIntegrationFlow.res\n",
      "src/screens/PGintegration/NewTracker.res\n",
      "src/screens/PGintegration/PostmanData.res\n",
      "src/screens/PGintegration/ShowFeature.res\n",
      "src/screens/PGintegration/ShowPgView.res\n",
      "src/screens/PGintegration/UploadPGDoc.res\n",
      "src/libraries/SyntaxHighlighter.res\n",
      "src/screens/PGintegration/EntryPoint.res\n",
      "src/screens/PGintegration/IntegrationTableEntities.res\n",
      "src/screens/PGintegration/IntegrationTables.res\n",
      "src/screens/PGintegration/PromptTesting.res\n",
      "src/screens/PGintegration/RequestCard.res\n",
      "src/screens/PGintegration/SideBar.res\n",
      "src/screens/PGintegration/UtilityFunction.res\n",
      "src/screens/PGintegration/AccuracyMetricEntity.res\n",
      "src/screens/PGintegration/AccuracyMetricesList.res\n"
     ]
    }
   ],
   "source": [
    "from jaf.types import Query \n",
    "\n",
    "q = Query()\n",
    "\n",
    "for res in result:\n",
    "    print(res.moduleName)\n",
    "    q.prompt = userPrompt.format(added=res.addedFunctions,modified=res.modifiedFunctions,deleted=res.deletedFunctions)\n",
    "    q.system_prompt = systemPrompt \n",
    "\n",
    "    llm(q)\n",
    "    parsed_resp = parse(q.response)\n",
    "    res.testCases = parsed_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = [] \n",
    "\n",
    "for res in result:\n",
    "    json_list.append(res.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/sakthi.n/Documents/Opensource/cada-rescript/llm_response.json\", \"w\") as f:\n",
    "    json.dump(json_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
